from swarms.models.base_llm import BaseLLM
from pydantic import BaseModel
from typing import List, Dict, Optional
import os

try:
    from openai import OpenAI
except ImportError:
    raise ImportError("OpenAI package is required for OpenRouter. Install with: pip install openai")


class OpenRouterRequest(BaseModel):
    model: str
    messages: List[Dict[str, str]] = []


class OpenRouterChat(BaseLLM):
    """
    A class representing an OpenRouter chat model that uses OpenAI-compatible API.

    Args:
        model_name (str): The name of the OpenRouter model (e.g., 'anthropic/claude-3-haiku', 'meta-llama/llama-3.1-8b-instruct').
        openrouter_api_key (str, optional): The API key for accessing the OpenRouter API. Defaults to None.
        system_prompt (str, optional): The system prompt for the chat model. Defaults to None.
        temperature (float, optional): Temperature for sampling. Defaults to 0.7.
        max_tokens (int, optional): Maximum tokens to generate. Defaults to 2000.
        *args: Variable length argument list.
        **kwargs: Arbitrary keyword arguments.

    Attributes:
        model_name (str): The name of the OpenRouter model.
        openrouter_api_key (str): The API key for accessing the OpenRouter API.
        system_prompt (str): The system prompt for the chat model.
        client: OpenAI client configured for OpenRouter.

    Methods:
        run(task, *args, **kwargs): Runs the chat model with the given task.
        __call__(task, *args, **kwargs): Alias for run method.

    Example:
        >>> from swarms.models import OpenRouterChat
        >>> llm = OpenRouterChat(
        ...     model_name="anthropic/claude-3-haiku",
        ...     openrouter_api_key="your-key-here"
        ... )
        >>> response = llm("Hello, how are you?")
    """

    def __init__(
        self,
        model_name: str,
        openrouter_api_key: Optional[str] = None,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 2000,
        *args,
        **kwargs,
    ):
        super().__init__(*args, **kwargs)
        self.model_name = model_name
        self.openrouter_api_key = openrouter_api_key or os.getenv("OPENROUTER_API_KEY")
        self.system_prompt = system_prompt
        self.temperature = temperature
        self.max_tokens = max_tokens

        if not self.openrouter_api_key:
            raise ValueError("OpenRouter API key is required. Set OPENROUTER_API_KEY environment variable or pass openrouter_api_key parameter.")

        # Initialize OpenAI client for OpenRouter
        self.client = OpenAI(
            api_key=self.openrouter_api_key,
            base_url="https://openrouter.ai/api/v1",
        )

    def run(self, task: str, *args, **kwargs) -> str:
        """
        Runs the chat model with the given task.

        Args:
            task (str): The user's task for the chat model.
            *args: Variable length argument list.
            **kwargs: Arbitrary keyword arguments.

        Returns:
            str: The response generated by the chat model.

        """
        messages = []
        
        if self.system_prompt:
            messages.append({"role": "system", "content": self.system_prompt})
        
        messages.append({"role": "user", "content": task})

        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=kwargs.get('temperature', self.temperature),
                max_tokens=kwargs.get('max_tokens', self.max_tokens),
                **{k: v for k, v in kwargs.items() if k not in ['temperature', 'max_tokens']}
            )
            return response.choices[0].message.content
        except Exception as e:
            raise RuntimeError(f"OpenRouter API error: {str(e)}")

    def __call__(self, task: str, *args, **kwargs) -> str:
        """Alias for run method to make the class callable."""
        return self.run(task, *args, **kwargs)
