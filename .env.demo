# Demo Environment Variables
# Copy this file to .env and configure your API keys

# === PRIMARY MODEL PROVIDERS ===

# OpenAI API Key (Premium models - GPT-4, GPT-3.5-turbo)
# OPENAI_API_KEY=your_openai_api_key_here

# OpenRouter API Key (Access to multiple providers through one API)
# OPENROUTER_API_KEY=your_openrouter_api_key_here

# === LOCAL MODEL PROVIDERS ===

# Ollama (Run models locally - no API key needed)
# Install from: https://ollama.ai
# Start with: ollama serve
# Pull models with: ollama pull llama3.1

# === ADDITIONAL PROVIDERS ===

# Anthropic API Key (Claude models)
# ANTHROPIC_API_KEY=your_anthropic_key_here

# Other supported LLM APIs
# GOOGLE_API_KEY=your_google_key_here
# HUGGINGFACE_API_TOKEN=your_hf_token_here

# === DEMO CONFIGURATION ===
DEMO_MODE=true
LOG_LEVEL=INFO
OUTPUT_DIR=research_output

# === MODEL PRIORITY ===
# The demo will automatically try providers in this order:
# 1. OpenAI (if OPENAI_API_KEY is set)
# 2. OpenRouter (if OPENROUTER_API_KEY is set) 
# 3. Ollama (if server is running locally)
# 4. Mock LLM (always available for demonstration)